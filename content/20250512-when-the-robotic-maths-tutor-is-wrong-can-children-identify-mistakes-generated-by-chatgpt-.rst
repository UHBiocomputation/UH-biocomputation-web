When the Robotic Maths Tutor is Wrong - Can Children Identify Mistakes Generated by ChatGPT?
#############################################################################################
:date: 2025-05-12 13:42:30
:author: Manal Helal
:category: Seminars
:tags: Atmospheric modeling, Brain, Chatbots, Cognition, Education, Educational Robots, Large language models, Large Language Models, Learning (artificial intelligence), LLM Mathematical Correctness, Mathematical models, Social Robotic
:slug: when-the-robotic-maths-tutor-is-wrong-can-children-identify-mistakes-generated-by-chatgpt-
:summary: Manal Helal's Journal Club session where she will talk about "When the Robotic Maths Tutor is Wrong - Can Children Identify Mistakes Generated by ChatGPT?".

On this week's Journal Club session, Manal Helal will talk about her work in the presentation entitled "When the Robotic Maths Tutor is Wrong - Can Children Identify Mistakes Generated by ChatGPT?".

------------

This study delves into integrating Large Language Models (LLMs), particularly ChatGPT-
powered robots, as educational tools in primary school mathematics. Against the backdrop
of Artificial Intelligence (AI) increasingly permeating educational settings, our
investigation focuses on the response of young learners to errors made by these LLM-
powered robots. Employing a user study approach, we conducted an experiment using the
Pepper robot in a primary school classroom environment, where 77 primary school students
from multiple grades (Year 3 to 5) took part in interacting with the robot. Our
statistically significant findings highlight that most students, regardless of the year
group, could discern between correct and incorrect responses generated by the robots,
demonstrating a promising level of understanding and engagement with the AI-driven
educational tool. Additionally, we observed that students' correctness in answering the
Maths questions significantly influenced their ability to identify errors, underscoring
the importance of prior knowledge in verifying LLM responses and detecting errors.
Additionally, we examined potential confounding factors such as age and gender. Our
findings underscore the importance of gradually integrating AI-powered educational tools
under the guidance of domain experts following thorough verification processes. Moreover,
our study calls for further research to establish best practices for implementing AI-
driven pedagogical approaches in educational settings.

|

Papers:

- M. Helal, P. Holthaus, L. Wood, V. Velmurugan, G. Lakatos, S. Moros, F. Amirabdollahian, `"When the Robotic Maths Tutor is Wrong - Can Children Identify Mistakes Generated by ChatGPT?"
  <https://doi.org/10.1109/AIRC61399.2024.10672220>`__, 2024, 83--90
- Helal M., "Beyond Accuracy: Primary Studentsâ€™ Critical Engagement with LLM-Generated Mathematics - A Study of Error Detection, Trust Calibration, and Educational Implications", under review 


**Date:**  2025/05/16 |br|
**Time:** 14:00 |br|
**Location**: SP3011 & online

.. |br| raw:: html

	<br />
